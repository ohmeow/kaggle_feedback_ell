# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_utils.ipynb.

# %% ../nbs/00_utils.ipynb 3
from __future__ import annotations

import abc, datetime, random, os
from pathlib import Path

import numpy as np
import torch
from torch import nn
from torch.nn import functional as F
from fastai.losses import CrossEntropyLossFlat
from fastai.test_utils import show_install
from sklearn.metrics import mean_squared_error

from fastai.metrics import rmse, AccumMetric
from fastcore.test import *


# %% auto 0
__all__ = ['default_seed', 'kaggle_comp', 'run_env', 'detect_env', 'print_dev_environment', 'get_paths', 'setup_comp',
           'comp_metric_score', 'MCRMSE', 'RMSELoss_0', 'MCRMSELoss', 'rev_phrase', 'CompTrainer', 'get_run_id']

# %% ../nbs/00_utils.ipynb 7
default_seed = int(os.getenv("RANDOM_SEED", 42))
kaggle_comp = os.getenv("KAGGLE_COMP", "feedback-prize-english-language-learning")


# %% ../nbs/00_utils.ipynb 9
def detect_env():
    """A helper function that detects where you are running code"""
    if os.environ.get("KAGGLE_KERNEL_RUN_TYPE", False):
        run_env = "kaggle"
    elif os.path.isdir("/content"):
        run_env = "colab"
    elif os.path.isdir("../nbs") or os.path.isdir("../../nbs"):
        run_env = "local_nb"
    else:
        run_env = "script"

    return run_env


run_env = detect_env()


# %% ../nbs/00_utils.ipynb 11
def print_dev_environment():
    """Provides details on your development environment including packages installed, cuda/cudnn availability, GPUs, etc."""
    print(show_install())


# %% ../nbs/00_utils.ipynb 14
def get_paths(override_project_root=None):
    """Returns data, models, and log folder paths based on your where you are running the code"""
    if run_env == "kaggle":
        data_path = Path(".")
        comp_data_path = clean_data_path = Path(f"../input/{kaggle_comp}")
        working_path = Path("/kaggle/working")
        models_path = working_path / "models"
        logs_path = working_path / "logs"

    elif run_env == "colab":
        proj_root_path = override_project_root or Path(".")

        data_path = proj_root_path
        comp_data_path = clean_data_path = data_path
        models_path = data_path / "models"
        logs_path = data_path / "logs"

    elif run_env == "local_nb":
        proj_root_path = override_project_root or Path("..")

        data_path = Path(proj_root_path / "data")
        comp_data_path = data_path / "comp"
        clean_data_path = data_path / "clean"
        models_path = Path(proj_root_path / "models")
        logs_path = Path(proj_root_path / "logs")

        comp_data_path.mkdir(parents=True, exist_ok=True)
        clean_data_path.mkdir(parents=True, exist_ok=True)

    elif run_env == "script":
        proj_root_path = override_project_root or Path(".")

        data_path = Path(proj_root_path / "data")
        comp_data_path = data_path / "comp"
        clean_data_path = data_path / "clean"
        models_path = Path(proj_root_path / "models")
        logs_path = Path(proj_root_path / "logs")

        comp_data_path.mkdir(parents=True, exist_ok=True)
        clean_data_path.mkdir(parents=True, exist_ok=True)

    try:
        models_path.mkdir(parents=True, exist_ok=True)
        logs_path.mkdir(parents=True, exist_ok=True)
    except:
        print("Unable to create models and logs folders")

    return data_path, comp_data_path, clean_data_path, models_path, logs_path


# %% ../nbs/00_utils.ipynb 15
def setup_comp(override_project_root=None, comp_data_path_override=None):
    """Ensures that the expected data, models, and logs folders exist and that the competition data exists in the 'comp_data_path'."""

    if comp_data_path_override is not None:
        comp_data_path = comp_data_path_override
    else:
        _, comp_data_path, *_ = get_paths(override_project_root)

    if run_env != "kaggle":
        from kaggle import api
        
        if not comp_data_path.exists() or not any(comp_data_path.iterdir()):
            import zipfile

            api.competition_download_cli(kaggle_comp)

            zipfile.ZipFile(f"{kaggle_comp}.zip").extractall(comp_data_path)
            Path(f"{kaggle_comp}.zip").unlink(missing_ok=True)

        return comp_data_path
    else:
        return Path(f"../input/{kaggle_comp}")


# %% ../nbs/00_utils.ipynb 18
def comp_metric_score(preds, targs):
    """This competition is evaluated using "columnwise root mean squared error". Expects numpy arrays."""
    len_target_cols = targs.shape[1]
    score = [0] * len_target_cols
    for i in range(len_target_cols):
        score[i] = np.sqrt(mean_squared_error(preds[:, i], targs[:, i]))
    return np.mean(score)

# %% ../nbs/00_utils.ipynb 19
def MCRMSE(dim_argmax=None, **kwargs):
    "columnwise root mean squared error for regression problem"
    def mcrmse(x,y): return comp_metric_score(x.cpu().numpy(),y.cpu().numpy())
    return AccumMetric(mcrmse, invert_arg=False, flatten=False, dim_argmax=dim_argmax, **kwargs)

# %% ../nbs/00_utils.ipynb 27
class RMSELoss_0(nn.Module):
    def __init__(self, eps=1e-6):
        super().__init__()
        self.mse = nn.MSELoss()
        self.eps = eps

    def forward(self, yhat, y):
        loss = torch.sqrt(self.mse(yhat, y) + self.eps)
        return loss


class MCRMSELoss(nn.Module):
    def __init__(self, num_scored=6):
        super().__init__()
        self.rmse = RMSELoss_0()
        self.num_scored = num_scored

    def forward(self, yhat, y):
        score = 0
        for i in range(self.num_scored):
            score += self.rmse(yhat[:, i], y[:, i]) / self.num_scored

        return score

# %% ../nbs/00_utils.ipynb 29
def rev_phrase(foo: str):
    return " ".join(foo.split()[::-1])

# %% ../nbs/00_utils.ipynb 32
class CompTrainer(abc.ABC):
    def __init__(self, train_config, model_name, model_output_path="models", log_output_path="logs", **kwargs):
        self.train_config = train_config
        self.model_name = model_name
        self.model_output_path = Path(model_output_path)
        self.log_output_path = Path(log_output_path)

    @abc.abstractmethod
    def train(self, CFG, data, experiment_name=None , n_fold=5, run_id=-1, grid_id=-1, seed=None, verbose: bool = True):
        pass

    @abc.abstractmethod
    def predict(self, model_name, data):
        pass

    def get_value_for(self, attr, CFG, default):
        val = getattr(CFG, attr, None)
        return val if val is not None else self.train_config.get(attr, default)


# %% ../nbs/00_utils.ipynb 34
def get_run_id():
    run_id = str(datetime.datetime.now())[:16].replace(":", "_").replace(" ", "_").replace("-", "_")
    return run_id

