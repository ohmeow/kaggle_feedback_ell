# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_pre_processing.ipynb.

# %% auto 0
__all__ = ['preprocess_data']

# %% ../nbs/02_pre_processing.ipynb 3
import argparse, os
from pathlib import Path

import pandas as pd
import nltk
from nltk.corpus import wordnet
from nltk.stem import WordNetLemmatizer

from fastai.callback.all import *
from sklearn import model_selection

from . import utils

# %% ../nbs/02_pre_processing.ipynb 6
def preprocess_data(ds: str = "train", preprocess: str = "basic", save_file: bool = True, return_file: bool = False):
    is_train = ds == "train"

    data_path, raw_data_path, clean_data_path, *_ = utils.get_paths()
    df = pd.read_csv(raw_data_path / f"{ds}.csv")

    # remove surrounding whitespace
    df["full_text"] = df["full_text"].str.strip()

    if save_file:
        df.to_csv(clean_data_path / f"preproc_{ds}.csv", index=False)

    if return_file:
        return df


# %% ../nbs/02_pre_processing.ipynb 9
if __name__ == "__main__" and utils.run_env != "local_nb":
    # instantiate argparser
    parser = argparse.ArgumentParser()

    # define args
    parser.add_argument("--ds", type=str, default="train")
    parser.add_argument("--preprocess", type=str, default="basic")
    args = parser.parse_args()

    preprocess_data(ds=args.ds, preprocess=args.preprocess, save_file=True, return_file=False)

