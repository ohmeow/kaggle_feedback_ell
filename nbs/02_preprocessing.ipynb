{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp preprocessing\n",
    "# |default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing\n",
    "\n",
    "> Preprocessing data primarily for feature engineering that may be helpful during training and postprocessing.  See Martin's EDA report for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import argparse, os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from fastai.callback.all import *\n",
    "from sklearn import model_selection\n",
    "\n",
    "from kaggle_comp import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "from fastcore.test import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def preprocess_data(ds: str = \"train\", preprocess: str = \"basic\", save_file: bool = True, return_file: bool = False):\n",
    "    is_train = ds == \"train\"\n",
    "\n",
    "    data_path, raw_data_path, clean_data_path, *_ = utils.get_paths()\n",
    "    df = pd.read_csv(raw_data_path / f\"{ds}.csv\")\n",
    "\n",
    "    # remove surrounding whitespace\n",
    "    df[\"full_text\"] = df[\"full_text\"].str.strip()\n",
    "\n",
    "    if save_file:\n",
    "        df.to_csv(clean_data_path / f\"preproc_{ds}.csv\", index=False)\n",
    "\n",
    "    if return_file:\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if utils.run_env == \"local_nb\":\n",
    "    preprocess_data(\"train\", preprocess=\"basic\")\n",
    "    preprocess_data(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local_nb'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.run_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == \"__main__\" and utils.run_env != \"local_nb\":\n",
    "    # instantiate argparser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # define args\n",
    "    parser.add_argument(\"--ds\", type=str, default=\"train\")\n",
    "    parser.add_argument(\"--preprocess\", type=str, default=\"basic\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    preprocess_data(ds=args.ds, preprocess=args.preprocess, save_file=True, return_file=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('kaggle_feedback_ell')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
